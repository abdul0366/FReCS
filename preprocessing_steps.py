# -*- coding: utf-8 -*-
"""Preprocessing-Steps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18rM5KgfUKE2-Mu2yTPsO6RHxLCdgv3xu

### Imports
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# General
import pandas as pd
import numpy as np
import re

# Plotting
import seaborn as sns
import matplotlib.pyplot as plt

# Gensim
import gensim
from gensim.utils import simple_preprocess

# NLTK
import nltk
from nltk.corpus import stopwords

from collections import Counter
from wordcloud import WordCloud

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

# %matplotlib inline

df = pd.read_csv('.../Dataset/Combined_Dataset.csv')

df

"""#### Convert tweets to string"""

df['text'] = df['tweet_text'].apply(str)
df

"""#### Check for duplicates"""

df.drop_duplicates(subset=['tweet_text'], keep='first', inplace=True)
df.shape



"""#### Count total number of characters and mean length of a tweet"""

count = df['text'].str.split().str.len()
count.index = count.index.astype(str) + ' words:'
count.sort_index(inplace=True)

print("Total number of words:", count.sum(), "words")

print("Mean number of words per tweet:", round(count.mean(),2), "words")

df["tweet_length"] = df["text"].str.len()
print("Total length of the dataset is:", df.tweet_length.sum(), "characters")

print("Mean Length of a tweet is:", round(df.tweet_length.mean(),0), "characters")
df = df.drop(['tweet_length'], axis=1)

"""####  Removing Twitter Handles (@user)"""

def remove_users(tweet, pattern1, pattern2):
    r = re.findall(pattern1, tweet)
    for i in r:
        tweet = re.sub(i, '', tweet)

    r = re.findall(pattern2, tweet)
    for i in r:
        tweet = re.sub(i, '', tweet)
    return tweet

df['tidy_tweet'] = np.vectorize(remove_users)(df['text'], "@ [\w]*", "@[\w]*")
df

"""#### Normalization"""

df['tidy_tweet'] = df['text'].str.lower()
df['tidy_tweet']

"""#### Remove Links"""

def remove_links(tweet):
    tweet_no_link = re.sub(r"http\S+", "", tweet)
    return tweet_no_link

df['tidy_tweet'] = np.vectorize(remove_links)(df['tidy_tweet'])

"""#### Removing Punctuations, Numbers, and Special Characters"""

import string
# Remove punctuation
punctuations = string.punctuation
df['tidy_tweet'] = df['tidy_tweet'].str.replace(f"[{punctuations}]", " ")

df['tidy_tweet']

"""#### Remove short words"""

df['tidy_tweet'] = df['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))
df['tidy_tweet']

"""#### Tokenize words and clean-up Punctuations"""

def tokenize(tweet):
    for word in tweet:
        yield(gensim.utils.simple_preprocess(str(word), deacc=True))

df['tidy_tweet_tokens'] = list(tokenize(df['tidy_tweet']))

# Join the tweet back together
def rejoin_words(row):
    words = row['tidy_tweet_tokens']
    joined_words = (" ".join(words))
    return joined_words

df['tidy_tweet_tokens'] = df.apply(rejoin_words, axis=1)



all_words1 = ' '.join([text for text in df['tidy_tweet_tokens']])
all_words1

# all_words1 = ' '.join([text for text in df['tidy_tweet']])
# all_words1

text_file = open("event.txt", "wt")
n = text_file.write(all_words1)
text_file.close()

wordcloud = WordCloud().generate(all_words1)
plt.figure(figsize=(12, 8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

wordcloud = WordCloud(width=900, height=600, random_state=21, max_font_size=110, background_color='black',
                      max_words=200,colormap='Dark2').generate(all_words1)

plt.figure(figsize=(12, 8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

"""#### Remove Stopwords"""

import nltk
nltk.download('stopwords')
# Prepare Stop Words
stop_words = stopwords.words('english')
stop_words.extend(['hurricane', 'hurricaneharvey', 'earthquake', 'sandy', 'harvey', 'Odile', 'odile', 'nepalearthquake', 'team', 'qatar', 'nepalquake'])

def remove_stopwords(tweets):
    return [[word for word in simple_preprocess(str(tweet)) if word not in stop_words] for tweet in tweets]

df['tokens_no_stop'] = remove_stopwords(df['tidy_tweet_tokens'])
df['tokens_no_stop']

"""#### Drop rows having less than three tokens  """

df['length'] = df['tokens_no_stop'].apply(len)
df = df.drop(df[df['length']<3].index)
df

"""#### WordCloud"""

# Join the tweet back together
def rejoin_words(row):
    words = row['tokens_no_stop']
    joined_words = (" ".join(words))
    return joined_words

df['no_stop_joined'] = df.apply(rejoin_words, axis=1)

all_words = ' '.join([text for text in df['no_stop_joined']])
all_words

text_file = open("event1.txt", "wt")
n = text_file.write(all_words)
text_file.close()

wordcloud = WordCloud(random_state=21, background_color='ghostwhite',
                      colormap='Set1').generate(all_words)
plt.figure(figsize=(12, 8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

wordcloud = WordCloud(width=900, height=600, random_state=21, max_font_size=110, background_color='ghostwhite',
                      max_words=200,colormap='Dark2').generate(all_words)

plt.figure(figsize=(12, 8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

wordcloud = WordCloud(width=900, height=600, random_state=21, max_font_size=110, background_color='ghostwhite',
                      max_words=200,colormap='Dark2').generate(all_words)

plt.figure(figsize=(12, 8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

"""#### Cleaning Effects - Length of tweets"""

df["tweet_length"] = df["text"].str.len()
df["cleaned_tweet_length"] = df["no_stop_joined"].str.len()
df_lengths = df[['tweet_length', 'cleaned_tweet_length']]
df_lengths

import seaborn as sns
import matplotlib.pyplot as plt

x1 = df_lengths.tweet_length
x2 = df_lengths.cleaned_tweet_length

plt.figure(figsize=(15,6))
plt.suptitle('Length of tweet as number of characters', fontsize=14, fontweight="bold")

# KDE Plot for Original Tweets
plt.subplot(1,2,1)
sns.kdeplot(x1, color="black", fill=True)
plt.title("Original Tweets",fontsize=12, fontweight="bold")
plt.xlabel("Number of characters", fontsize=12)
plt.ylabel("Density", fontsize=12)
plt.xlim([0,400])

# KDE Plot for Cleaned Tweets
plt.subplot(1,2,2)
sns.kdeplot(x2, color="black", fill=True)
plt.title("Cleaned Tweets",fontsize=12, fontweight="bold")
plt.xlabel("Number of characters", fontsize=12)
plt.ylabel("Density", fontsize=12)
plt.xlim([0,400])

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Sample Data (Assuming df_lengths is already defined)
x1 = df_lengths.tweet_length
x2 = df_lengths.cleaned_tweet_length

plt.figure(figsize=(25, 10))
plt.suptitle('Length of Tweet as Number of Characters', fontsize=26, fontweight="bold")

# Set the background style for better visibility
sns.set_style("whitegrid")

# KDE Plot for Original Tweets
plt.subplot(1, 2, 1)
sns.kdeplot(x1, color="skyblue", fill=True, lw=3)
plt.title("Original Tweets", fontsize=20, fontweight="bold")
plt.xlabel("Number of Characters", fontsize=20, fontweight="bold")
plt.ylabel("Density", fontsize=20, fontweight="bold")
plt.xlim([0, 400])
plt.xticks(fontsize=20, fontweight="bold")
plt.yticks(fontsize=20, fontweight="bold")

# KDE Plot for Cleaned Tweets
plt.subplot(1, 2, 2)
sns.kdeplot(x2, color="lightcoral", fill=True, lw=3)
plt.title("Cleaned Tweets", fontsize=20, fontweight="bold")
plt.xlabel("Number of Characters", fontsize=20, fontweight="bold")
plt.ylabel("Density", fontsize=20, fontweight="bold")
plt.xlim([0, 400])
plt.xticks(fontsize=20, fontweight="bold")
plt.yticks(fontsize=20, fontweight="bold")

plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd



x1 = df_lengths.tweet_length
x2 = df_lengths.cleaned_tweet_length

plt.figure(figsize=(25, 10))
plt.suptitle('Tweet Length Measured in Number of Characters', fontsize=30, fontweight="bold")

# Color settings
original_tweet_color = "#1f77b4"
cleaned_tweet_color = "#ff7f0e"

# KDE Plot for Original Tweets
plt.subplot(1, 2, 1)
sns.kdeplot(x1, color=original_tweet_color, fill=True, lw=3)
plt.title("Before Cleaning", fontsize=25, fontweight="bold")
plt.xlabel("Number of Characters", fontsize=20, fontweight="bold")
plt.ylabel("Frequency", fontsize=20, fontweight="bold")
plt.xlim([0, 400])
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)

# KDE Plot for Cleaned Tweets
plt.subplot(1, 2, 2)
sns.kdeplot(x2, color=cleaned_tweet_color, fill=True, lw=3)
plt.title("After Cleaning", fontsize=25, fontweight="bold")
plt.xlabel("Number of Characters", fontsize=20, fontweight="bold")
plt.ylabel("Frequency", fontsize=20, fontweight="bold")
plt.xlim([0, 400])
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)

# Adjust background color for more contrast
sns.set_style("whitegrid")

plt.show()

x1 = df_lengths.tweet_length
x2 = df_lengths.cleaned_tweet_length
plt.figure(figsize=(15,6))
plt.suptitle('Length of tweet as number of characters', fontsize=14, fontweight="bold")
plt.subplot(1,2,1)
sns.distplot(x1, color="black", label="No. Words", bins=35, hist_kws={"alpha": 0.5,"rwidth":0.8})
plt.title("Original Tweets",fontsize=12, fontweight="bold")
plt.xlabel("Number of characters", fontsize=12)
plt.ylabel("Frequency", fontsize=12)
plt.xlim([0,400])

# Chart 2: Derivative Function
plt.subplot(1,2,2)
sns.distplot(x2, color="black", label="No. Words", bins=17, hist_kws={"alpha": 0.5, "rwidth":0.8})
plt.title("Cleaned Tweets",fontsize=12, fontweight="bold")
plt.xlabel("Number of characters", fontsize=12)
plt.ylabel("Frequency", fontsize=12)
plt.xlim([0,400])

plt.show()

"""#### Cleaning Effects - Number of Words"""

df["tweet_words"] = df['text'].str.split().str.len()
df["cleaned_tweet_words"] = df["no_stop_joined"].str.split().str.len()
df_lengths = df[['tweet_words', 'cleaned_tweet_words']]
df_lengths

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd



x_1 = df_lengths.tweet_words
x_2 = df_lengths.cleaned_tweet_words

plt.figure(figsize=(25, 10))
plt.suptitle('Tweet Length Measured in Number of Words', fontsize=30, fontweight="bold")

# Color settings
# Color settings
original_tweet_color = "#4a4ae6"  # Deep blue
cleaned_tweet_color = "#006400"  # Bright red

# KDE Plot for Original Tweets
plt.subplot(1, 2, 1)
sns.kdeplot(x_1, color=original_tweet_color, fill=True, lw=3)
plt.title("Before Cleaning", fontsize=25, fontweight="bold")
plt.xlabel("Number of words", fontsize=20, fontweight="bold")
plt.ylabel("Frequency", fontsize=20, fontweight="bold")
plt.xlim([0, 70])
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)

# KDE Plot for Cleaned Tweets
plt.subplot(1, 2, 2)
sns.kdeplot(x_2, color=cleaned_tweet_color, fill=True, lw=3)
plt.title("After Cleaning", fontsize=25, fontweight="bold")
plt.xlabel("Number of words", fontsize=20, fontweight="bold")
plt.ylabel("Frequency", fontsize=20, fontweight="bold")
plt.xlim([0, 50])
plt.xticks(fontsize=18)
plt.yticks(fontsize=18)

# Adjust background color for more contrast
sns.set_style("whitegrid")

plt.show()





x_1 = df_lengths.tweet_words
x_2 = df_lengths.cleaned_tweet_words
plt.figure(figsize=(15,6))
plt.suptitle('Length of tweet as number of words.', fontsize=14, fontweight="bold")
plt.subplot(1,2,1)
sns.distplot(x_1, color="black", label="No. Words", bins=25, hist_kws={"alpha": 0.5,"rwidth":0.8})
plt.title("Original Tweets",fontsize=12, fontweight="bold")
plt.xlabel("Number of words", fontsize=12)
plt.ylabel("Frequency", fontsize=12)
plt.xlim([0,70])



# Chart 2: Derivative Function
plt.subplot(1,2,2)
sns.distplot(x_2, color="black", label="No. Words", bins=15, hist_kws={"alpha": 0.5, "rwidth":0.8})
plt.title("Cleaned Tweets",fontsize=12, fontweight="bold")
plt.xlabel("Number of words", fontsize=12)
plt.ylabel("Frequency", fontsize=12)
plt.xlim([0,50])

plt.show()

df = df.drop(['tweet_length', 'cleaned_tweet_length', 'tweet_words', 'cleaned_tweet_words'], axis=1)

"""#### Top 25 Most frequent Words  """

word_freq = pd.Series(np.concatenate([x.split() for x in df.no_stop_joined])).value_counts()

word_df = pd.Series.to_frame(word_freq)
word_df['word'] = list(word_df.index)
word_df.reset_index(drop=True, inplace=True)
word_df.columns = ['freq', 'word']

label = word_df['word'].head(50)
freq = word_df['freq'].head(50)
index = np.arange(len(freq))

print("Unique words:", len(word_df))
plt.figure(figsize=(12,9))
plt.bar(index, freq, alpha=0.8, color= 'black')
plt.xlabel('Words', fontsize=13)
plt.ylabel('Frequency', fontsize=13)
plt.xticks(index, label, fontsize=11, rotation=90, fontweight="bold")
plt.title('Top 50 Words after preprocessing', fontsize=12, fontweight="bold")
plt.show()

"""#### Save Dataframe"""

df.to_csv('.../Dataset/Preprocessed_Combined_Dataset.csv', index=False)